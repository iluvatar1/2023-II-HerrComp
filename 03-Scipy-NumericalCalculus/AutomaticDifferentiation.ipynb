{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bdb43a8-bbf2-4f7d-9ad4-c42fdd92de00",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba1c46c-bbc6-446d-b610-8095fc85ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"NONE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fec727d-1179-44c4-8e9f-dd34ecf34e74",
   "metadata": {},
   "source": [
    "# Automatic differentiation\n",
    "\n",
    "Refs:\n",
    "- https://alexey.radul.name/ideas/2013/introduction-to-automatic-differentiation/\n",
    "- http://autodiff.org/\n",
    "- https://www.kaggle.com/code/borisettinger/gentle-introduction-to-automatic-differentiation\n",
    "- https://en.wikipedia.org/wiki/Automatic_differentiation?useskin=vector\n",
    "- https://towardsdatascience.com/pytorch-autograd-understanding-the-heart-of-pytorchs-magic-2686cd94ec95\n",
    "- https://d2l.ai/chapter_preliminaries/autograd.html\n",
    "- https://arxiv.org/abs/1502.05767\n",
    "- https://www.youtube.com/watch?v=wG_nF1awSSY&t=0s\n",
    "- https://www.youtube.com/watch?v=ZGSUrfJcXmA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddc14db-43be-49c6-9396-c86bc7ba5195",
   "metadata": {},
   "source": [
    "How to differentiate in the computer?\n",
    "- **Exact**: Not always available. Imagine a neural network with millions of parameters, you cannot just do it manually. \n",
    "- **Symbolic** (sympy, mathematica, ...): Expression tree explossion (see, for instance, the multiplication rule). Derivative of data struct?\n",
    "- **Finite differences**: Stability and precision. O(n) evaluations for n-dimensional gradient.\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/4/41/AbsoluteErrorNumericalDifferentiationExample.png\" alt=\"Image Description\" width=\"600\">\n",
    "    <figcaption>From: \"https://upload.wikimedia.org/wikipedia/commons/4/41/AbsoluteErrorNumericalDifferentiationExample.png\"</figcaption>\n",
    "</div>\n",
    "- **Automatic differentiation** : Chain rule applied to intermediate values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3db28b-4fdc-4952-be84-b98bea48073b",
   "metadata": {},
   "source": [
    "## Applications of Automatic Differentiation\n",
    "- Optimization (multi-dimensional) based on gradient computations (neural networks)\n",
    "- Sensitivity analysis ($\\partial(result)/\\partial(input)$)\n",
    "- Physical modeling (computing forces as derivatives of potentials, computing equations of motion from Lagrange or Hamiltonian equations)\n",
    "- Probabilistic inference (Hamiltonian Monte Carlo)\n",
    "- Machine learning\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ab5184-eaa0-45a6-9316-d6a9db17a115",
   "metadata": {},
   "source": [
    "# Forward-mode (directional derivatives): Dual numbers\n",
    "Based in infinitesimal calculus: $\\epsilon^2 = 0$. So a Taylor expression for an approximation is\n",
    "$$\n",
    "f(x+\\epsilon) = f(x) + \\epsilon f'(x) + 0\n",
    "$$\n",
    "The pair $(x, f'(x))$ is called a dual pair. And there are operating rules such us\n",
    "$$\n",
    "(x+\\epsilon x')(y + \\epsilon y') = (x+y)+ \\epsilon(x' + y')\n",
    "$$\n",
    "$$\n",
    "f(x +\\epsilon x') = f(x) + \\epsilon f'(x)x',\n",
    "$$\n",
    "By extending the basic operations to this dual numbers, we can compute the derivative automatically by evaluating the epsilon coefficient of $dual-version(f(x+epsilon 1))$\n",
    "\n",
    "The following is a simple implementation (https://www.kaggle.com/code/borisettinger/gentle-introduction-to-automatic-differentiation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4716e32c-bb51-43c7-800e-25a731ead01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualBasic(object):\n",
    "    def __init__(self, val, eps):\n",
    "        self.val = val\n",
    "        self.eps = eps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c205e68d-273d-431e-a9a9-cf1244d36374",
   "metadata": {},
   "source": [
    "Python magics for some basic ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1a9954-3fe4-4e85-bc68-3cde3b8533e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualBasicEnhanced(object):\n",
    "    def __init__(self, *args):\n",
    "        if len(args) == 2:\n",
    "            value, eps = args\n",
    "        elif len(args) == 1:\n",
    "            if isinstance(args[0], (float, int)):\n",
    "                value, eps = args[0], 0\n",
    "            else:\n",
    "                value, eps = args[0].value, args[0].eps\n",
    "        self.value = value\n",
    "        self.eps = eps\n",
    "        \n",
    "    def __abs__(self):\n",
    "        return abs(self.value)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Dual({}, {})\".format(self.value, self.eps)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a572e-3ed3-47d3-8f6a-1443efcd02f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualArith(object):\n",
    "    def __add__(self, other):\n",
    "        other = Dual(other)\n",
    "        return Dual(self.value + other.value, self.eps + other.eps)\n",
    "    \n",
    "    def __sub__(self, other):\n",
    "        other = Dual(other)\n",
    "        return Dual(self.value - other.value, self.eps - other.eps)\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        other = Dual(other)\n",
    "        return Dual(self.value * other.value, self.eps * other.value + self.value * other.eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3ec542-1ebb-4462-8c3c-63d19c03acd8",
   "metadata": {},
   "source": [
    "And also include division:\n",
    "$$\n",
    "\\frac{1}{x+ae} = \\frac{1}{x} - \\epsilon \\frac{a}{x^2},\n",
    "$$\n",
    "so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2370d6a-3301-4f9d-bf33-b82d46c06e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualDiv(object):\n",
    "        def __truediv__(self, other):\n",
    "            other = Dual(other)\n",
    "            if abs(other.value) == 0:\n",
    "                raise ZeroDivisionError\n",
    "            else:\n",
    "                return Dual(self.value / other.value, \n",
    "                            self.eps / other.value - self.value / (other.value)**2 * other.eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ae4d88-a7a4-4f71-8f7b-22c2c77fbf43",
   "metadata": {},
   "source": [
    "Now this is the dual class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e200ba-2683-4ab3-8c1c-af215b77b636",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dual(DualBasicEnhanced, DualArith, DualDiv):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e757296e-5a1a-4c73-9a27-6f5da4908fdd",
   "metadata": {},
   "source": [
    "This is now an example for the automatic derivative of $x^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e443677-63d9-4eed-b5ec-394e8c962caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x*x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca9ffe7-940d-47c4-a53a-8d481d41d13f",
   "metadata": {},
   "source": [
    "If we want to compute the derivative at $x=3$, we use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d27d582-a683-49d5-abfa-185146680aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "square(Dual(3.1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076c518-97f7-4f4b-b4af-2a233e45a794",
   "metadata": {},
   "source": [
    "As you can see, in the primal part we have $3^2 = 9$, and on the dual part we have the derivative evaluated at $x=3$.\n",
    "\n",
    "Now let's use another function, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b90717c-fb06-431b-8fba-9c1c4cb33992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return x*x*x\n",
    "cube(Dual(2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bfc80d-b181-4446-b13f-21c3d66e4937",
   "metadata": {},
   "source": [
    "Let's plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7be6f7-042e-48d7-97ae-7536c7e0f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set_context(\"poster\")\n",
    "# Data\n",
    "x = np.linspace(0.0, 10.0, 100)\n",
    "y = square(x)\n",
    "yprime = square(Dual(x, 1))\n",
    "\n",
    "# Plot\n",
    "sns.lineplot(x=x, y=y, label=\"y\")\n",
    "sns.scatterplot(x=x[::5], y=yprime.value[::5], marker=\"o\", label=\"yprime.value\", color=\"red\")\n",
    "sns.lineplot(x=x, y=yprime.eps, label=\"yprime.eps\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81238e97-e0e6-49b5-a3eb-c21fe775722b",
   "metadata": {},
   "source": [
    "What about the error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746e8e4-797a-43a6-bedc-98afeded9074",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.abs(1-yprime.eps/(2*x)))\n",
    "sns.lineplot(x=x, y=np.abs(1-yprime.eps/(2*x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c4055-87cd-47eb-82c0-bbe871ccf69f",
   "metadata": {},
   "source": [
    "# More general implementation\n",
    "What about other functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cff647-de27-4ace-84db-40bf7ada2576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myexp(x):\n",
    "    return np.exp(x)\n",
    "myexp(Dual(3,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6856029-e774-42f7-97b7-c9a3c13f73f9",
   "metadata": {},
   "source": [
    "We need to use specialized libraries that have already and correctly implemented automatic differentiation, like\n",
    "- pytorch autograd: https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
    "- Tensorflow autodiff: https://www.tensorflow.org/guide/autodiff\n",
    "- numpy autograd: https://github.com/HIPS/autograd\n",
    "- ...\n",
    "\n",
    "# Using pytorch\n",
    "- https://pytorch.org/tutorials/intermediate/forward_ad_usage.html\n",
    "- https://towardsdatascience.com/getting-started-with-pytorch-part-1-understanding-how-automatic-differentiation-works-5008282073ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b84265d-786f-46e3-aa85-cfd32c1af59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "#!conda install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fdbddf-10d0-42aa-9cb3-4ba5b4622f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example from https://sebarnold.net/tutorials/beginner/blitz/autograd_tutorial.html\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6580066b-0f30-4643-981f-be20676805be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.ones(2, 2), requires_grad=True)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d9f39-b54e-4068-bdf5-b268bf2e185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42499c-5d09-422c-b2a1-2dec15818e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b892d6de-f975-47b8-bd60-939e2f1bd96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01827a6-fceb-4140-a214-88bb5e40fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d14aa-8b11-4e07-a582-500017efb3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c23fd3d-c1cf-4aa5-a7ea-a9f8319aab74",
   "metadata": {},
   "source": [
    "## Original example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fbfaea-5b2f-4b64-9892-25e252b7bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "\n",
    "x = torch.linspace(0.0, 1.0, 100, requires_grad=True)\n",
    "y = torch.exp(2*x)\n",
    "# Compute the gradient using torch.autograd.grad\n",
    "grads = torch.autograd.grad(y, x, torch.ones_like(y), create_graph=True)[0]\n",
    "# Convert torch tensors to NumPy arrays for plotting\n",
    "x_values = x.detach().numpy()\n",
    "y_values = y.detach().numpy()\n",
    "dy_dx_values = grads.detach().numpy()\n",
    "\n",
    "# Plot y and dy_dx\n",
    "sns.lineplot(x=x_values, y = y_values, label=rf'$\\exp(2x)$')\n",
    "sns.lineplot(x=x_values, y = dy_dx_values, label=rf'$dy/dx$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe18f867-a32c-4496-9eec-d8409cc98b98",
   "metadata": {},
   "source": [
    "# Using tensorflow\n",
    "- https://www.tensorflow.org/guide/autodiff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e372dbeb-b5ae-4cf0-b149-8f1862f843b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install tensorflow\n",
    "#!conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06894e6-07ec-4c1f-b3ab-8ee3e8dbe01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22cd66c-5311-42a8-872b-9b22f1f9d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3.0)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abaf6fe-4d90-4a6a-822e-a4dd42748e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54aaf85-cc71-47f3-80a6-3d2acd461257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dy = 2x * dx\n",
    "dy_dx = tape.gradient(y, x)\n",
    "dy_dx.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee98291-d35e-43c3-a779-e64d49b67095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.linspace(0.0, 10.0, 100)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)  # You need to watch the variable x explicitly.\n",
    "    y = x**2\n",
    "#print(y)\n",
    "dy_dx = tape.gradient(y, x)\n",
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9381f18-6cbe-4371-87ef-97f60c7273f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TensorFlow tensors to NumPy arrays for plotting\n",
    "x_values = x.numpy()\n",
    "y_values = y.numpy()\n",
    "dy_dx_values = dy_dx.numpy()\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "\n",
    "# Plot y and dy_dx\n",
    "sns.lineplot(x=x_values, y=y_values, label=rf'$y = x^2$')\n",
    "sns.lineplot(x=x_values, y=dy_dx_values, label=rf'$dy/dx$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeaa8cd-f1bc-4ee7-915e-f974460c2d7f",
   "metadata": {},
   "source": [
    "## Exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a28b89-3bc5-4fbe-8fa5-7949d7184620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.linspace(0.0, 1.23, 100)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x)  # You need to watch the variable x explicitly.\n",
    "    y = tf.exp(2*x)\n",
    "#print(y)\n",
    "dy_dx = tape.gradient(y, x)\n",
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab697c3e-76d2-429d-b56e-4f98303194ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TensorFlow tensors to NumPy arrays for plotting\n",
    "x_values = x.numpy()\n",
    "y_values = y.numpy()\n",
    "dy_dx_values = dy_dx.numpy()\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "\n",
    "# Plot y and dy_dx\n",
    "sns.lineplot(x=x_values, y=y_values, label=rf'$y = exp(2x)$')\n",
    "sns.lineplot(x=x_values, y=dy_dx_values, label=rf'$dy/dx$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353a3136-d6ce-4f9d-8750-98681c6f1a63",
   "metadata": {},
   "source": [
    "# Implementation using autograd\n",
    "- https://github.com/HIPS/autograd\n",
    "You will do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6093569-3d84-43b9-8b8a-337eb07c6ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
